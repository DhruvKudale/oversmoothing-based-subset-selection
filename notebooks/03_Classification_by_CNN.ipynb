{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since stanfordnlp/imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /home/dhruv/.cache/huggingface/datasets/stanfordnlp___imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Sat Apr 20 22:44:49 2024).\n"
     ]
    }
   ],
   "source": [
    "# # GLUE\n",
    "# dataset = load_dataset(\"glue\", \"sst2\")\n",
    "# val_dataset = dataset[\"validation\"]\n",
    "\n",
    "dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture for 1D vectors\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(in_channels = 1, out_channels = 32, kernel_size = 3)\n",
    "#         self.conv2 = nn.Conv1d(in_channels = 32, out_channels = 32, kernel_size = 3)\n",
    "#         self.conv3 = nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3)\n",
    "#         self.pool = nn.MaxPool1d(kernel_size = 2)\n",
    "        self.fc1 = nn.Linear(768, 512)  # Adjust input size according to your data\n",
    "        self.fc2 = nn.Linear(512, 1)      # Output layer with 1 neuron for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "#         x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "#         x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "#         x = x.view(-1, 16 * 94)  # Adjust the size according to the output size of the last convolutional layer\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))  # Sigmoid activation for binary classification\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data loader for demonstration\n",
    "class SampleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Training Data\n",
    "\n",
    "# Read pkl file \n",
    "with open('imdb-train-768.pkl', 'rb') as f:\n",
    "    vectors = pickle.load(f)\n",
    "    \n",
    "X = np.array(vectors)\n",
    "\n",
    "labels = []\n",
    "for item in train_dataset:\n",
    "    labels.append(item['label'])\n",
    "    \n",
    "Y = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining which Subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Instance Scores\n",
    "with open('instance-scores-IMDB-L2-30-40-30.pkl', 'rb') as f:\n",
    "    instance_scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eff = []\n",
    "Y_eff = []\n",
    "\n",
    "M = len(instance_scores)\n",
    "for i in range(M):\n",
    "    if instance_scores[i] < -0.005 or instance_scores[i] > 0.025 or 1:\n",
    "        X_eff.append(X[i])\n",
    "        Y_eff.append(Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 samples selected\n"
     ]
    }
   ],
   "source": [
    "N = len(X_eff)\n",
    "X_train = torch.from_numpy(np.array(X_eff).reshape(N, 1, 768))\n",
    "Y_train = torch.from_numpy(np.array(Y_eff).reshape(N, 1, 1)).float()\n",
    "print(str(N) + ' samples selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 12500\n",
      "Class 1: 12500\n"
     ]
    }
   ],
   "source": [
    "c0 = 0\n",
    "c1 = 0\n",
    "for i in Y_eff:\n",
    "    if i == 0:\n",
    "        c0 += 1\n",
    "    else:\n",
    "        c1 += 1\n",
    "        \n",
    "print('Class 0: ' + str(c0))\n",
    "print('Class 1: ' + str(c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.0692\n",
      "[1,   110] loss: 0.6816\n",
      "[1,   210] loss: 0.6481\n",
      "[1,   310] loss: 0.5975\n",
      "[1,   410] loss: 0.5426\n",
      "[1,   510] loss: 0.4875\n",
      "[1,   610] loss: 0.4459\n",
      "[1,   710] loss: 0.4175\n",
      "[2,    10] loss: 0.0356\n",
      "[2,   110] loss: 0.3704\n",
      "[2,   210] loss: 0.3567\n",
      "[2,   310] loss: 0.3580\n",
      "[2,   410] loss: 0.3553\n",
      "[2,   510] loss: 0.3351\n",
      "[2,   610] loss: 0.3300\n",
      "[2,   710] loss: 0.3321\n",
      "[3,    10] loss: 0.0359\n",
      "[3,   110] loss: 0.3186\n",
      "[3,   210] loss: 0.3141\n",
      "[3,   310] loss: 0.3066\n",
      "[3,   410] loss: 0.2998\n",
      "[3,   510] loss: 0.3100\n",
      "[3,   610] loss: 0.3087\n",
      "[3,   710] loss: 0.3013\n",
      "[4,    10] loss: 0.0296\n",
      "[4,   110] loss: 0.2911\n",
      "[4,   210] loss: 0.2862\n",
      "[4,   310] loss: 0.2954\n",
      "[4,   410] loss: 0.2971\n",
      "[4,   510] loss: 0.2918\n",
      "[4,   610] loss: 0.2843\n",
      "[4,   710] loss: 0.2960\n",
      "[5,    10] loss: 0.0284\n",
      "[5,   110] loss: 0.2963\n",
      "[5,   210] loss: 0.2877\n",
      "[5,   310] loss: 0.2720\n",
      "[5,   410] loss: 0.2855\n",
      "[5,   510] loss: 0.2782\n",
      "[5,   610] loss: 0.2824\n",
      "[5,   710] loss: 0.2596\n",
      "[6,    10] loss: 0.0312\n",
      "[6,   110] loss: 0.2707\n",
      "[6,   210] loss: 0.2791\n",
      "[6,   310] loss: 0.2664\n",
      "[6,   410] loss: 0.2656\n",
      "[6,   510] loss: 0.2794\n",
      "[6,   610] loss: 0.2851\n",
      "[6,   710] loss: 0.2792\n",
      "[7,    10] loss: 0.0265\n",
      "[7,   110] loss: 0.2686\n",
      "[7,   210] loss: 0.2993\n",
      "[7,   310] loss: 0.2640\n",
      "[7,   410] loss: 0.2722\n",
      "[7,   510] loss: 0.2711\n",
      "[7,   610] loss: 0.2567\n",
      "[7,   710] loss: 0.2876\n",
      "[8,    10] loss: 0.0253\n",
      "[8,   110] loss: 0.2689\n",
      "[8,   210] loss: 0.2733\n",
      "[8,   310] loss: 0.2648\n",
      "[8,   410] loss: 0.2610\n",
      "[8,   510] loss: 0.2895\n",
      "[8,   610] loss: 0.2518\n",
      "[8,   710] loss: 0.2807\n",
      "[9,    10] loss: 0.0292\n",
      "[9,   110] loss: 0.2814\n",
      "[9,   210] loss: 0.2658\n",
      "[9,   310] loss: 0.2774\n",
      "[9,   410] loss: 0.2585\n",
      "[9,   510] loss: 0.2650\n",
      "[9,   610] loss: 0.2686\n",
      "[9,   710] loss: 0.2551\n",
      "[10,    10] loss: 0.0238\n",
      "[10,   110] loss: 0.2698\n",
      "[10,   210] loss: 0.2664\n",
      "[10,   310] loss: 0.2454\n",
      "[10,   410] loss: 0.2755\n",
      "[10,   510] loss: 0.2774\n",
      "[10,   610] loss: 0.2605\n",
      "[10,   710] loss: 0.2635\n",
      "[11,    10] loss: 0.0239\n",
      "[11,   110] loss: 0.2733\n",
      "[11,   210] loss: 0.2685\n",
      "[11,   310] loss: 0.2648\n",
      "[11,   410] loss: 0.2594\n",
      "[11,   510] loss: 0.2614\n",
      "[11,   610] loss: 0.2551\n",
      "[11,   710] loss: 0.2565\n",
      "[12,    10] loss: 0.0295\n",
      "[12,   110] loss: 0.2546\n",
      "[12,   210] loss: 0.2490\n",
      "[12,   310] loss: 0.2761\n",
      "[12,   410] loss: 0.2696\n",
      "[12,   510] loss: 0.2671\n",
      "[12,   610] loss: 0.2588\n",
      "[12,   710] loss: 0.2442\n",
      "[13,    10] loss: 0.0281\n",
      "[13,   110] loss: 0.2481\n",
      "[13,   210] loss: 0.2663\n",
      "[13,   310] loss: 0.2467\n",
      "[13,   410] loss: 0.2616\n",
      "[13,   510] loss: 0.2583\n",
      "[13,   610] loss: 0.2580\n",
      "[13,   710] loss: 0.2719\n",
      "[14,    10] loss: 0.0228\n",
      "[14,   110] loss: 0.2613\n",
      "[14,   210] loss: 0.2535\n",
      "[14,   310] loss: 0.2540\n",
      "[14,   410] loss: 0.2514\n",
      "[14,   510] loss: 0.2688\n",
      "[14,   610] loss: 0.2500\n",
      "[14,   710] loss: 0.2575\n",
      "[15,    10] loss: 0.0304\n",
      "[15,   110] loss: 0.2482\n",
      "[15,   210] loss: 0.2593\n",
      "[15,   310] loss: 0.2570\n",
      "[15,   410] loss: 0.2484\n",
      "[15,   510] loss: 0.2573\n",
      "[15,   610] loss: 0.2488\n",
      "[15,   710] loss: 0.2601\n",
      "[16,    10] loss: 0.0256\n",
      "[16,   110] loss: 0.2474\n",
      "[16,   210] loss: 0.2569\n",
      "[16,   310] loss: 0.2490\n",
      "[16,   410] loss: 0.2518\n",
      "[16,   510] loss: 0.2653\n",
      "[16,   610] loss: 0.2452\n",
      "[16,   710] loss: 0.2472\n",
      "[17,    10] loss: 0.0282\n",
      "[17,   110] loss: 0.2541\n",
      "[17,   210] loss: 0.2460\n",
      "[17,   310] loss: 0.2563\n",
      "[17,   410] loss: 0.2447\n",
      "[17,   510] loss: 0.2407\n",
      "[17,   610] loss: 0.2604\n",
      "[17,   710] loss: 0.2622\n",
      "[18,    10] loss: 0.0321\n",
      "[18,   110] loss: 0.2390\n",
      "[18,   210] loss: 0.2594\n",
      "[18,   310] loss: 0.2530\n",
      "[18,   410] loss: 0.2443\n",
      "[18,   510] loss: 0.2536\n",
      "[18,   610] loss: 0.2630\n",
      "[18,   710] loss: 0.2512\n",
      "[19,    10] loss: 0.0279\n",
      "[19,   110] loss: 0.2490\n",
      "[19,   210] loss: 0.2467\n",
      "[19,   310] loss: 0.2676\n",
      "[19,   410] loss: 0.2706\n",
      "[19,   510] loss: 0.2463\n",
      "[19,   610] loss: 0.2483\n",
      "[19,   710] loss: 0.2353\n",
      "[20,    10] loss: 0.0199\n",
      "[20,   110] loss: 0.2539\n",
      "[20,   210] loss: 0.2576\n",
      "[20,   310] loss: 0.2414\n",
      "[20,   410] loss: 0.2523\n",
      "[20,   510] loss: 0.2525\n",
      "[20,   610] loss: 0.2578\n",
      "[20,   710] loss: 0.2403\n",
      "[21,    10] loss: 0.0241\n",
      "[21,   110] loss: 0.2495\n",
      "[21,   210] loss: 0.2561\n",
      "[21,   310] loss: 0.2496\n",
      "[21,   410] loss: 0.2428\n",
      "[21,   510] loss: 0.2519\n",
      "[21,   610] loss: 0.2583\n",
      "[21,   710] loss: 0.2315\n",
      "[22,    10] loss: 0.0252\n",
      "[22,   110] loss: 0.2475\n",
      "[22,   210] loss: 0.2416\n",
      "[22,   310] loss: 0.2327\n",
      "[22,   410] loss: 0.2397\n",
      "[22,   510] loss: 0.2729\n",
      "[22,   610] loss: 0.2344\n",
      "[22,   710] loss: 0.2442\n",
      "[23,    10] loss: 0.0243\n",
      "[23,   110] loss: 0.2415\n",
      "[23,   210] loss: 0.2554\n",
      "[23,   310] loss: 0.2314\n",
      "[23,   410] loss: 0.2405\n",
      "[23,   510] loss: 0.2549\n",
      "[23,   610] loss: 0.2470\n",
      "[23,   710] loss: 0.2578\n",
      "[24,    10] loss: 0.0265\n",
      "[24,   110] loss: 0.2420\n",
      "[24,   210] loss: 0.2465\n",
      "[24,   310] loss: 0.2407\n",
      "[24,   410] loss: 0.2468\n",
      "[24,   510] loss: 0.2500\n",
      "[24,   610] loss: 0.2364\n",
      "[24,   710] loss: 0.2486\n",
      "[25,    10] loss: 0.0227\n",
      "[25,   110] loss: 0.2593\n",
      "[25,   210] loss: 0.2430\n",
      "[25,   310] loss: 0.2499\n",
      "[25,   410] loss: 0.2315\n",
      "[25,   510] loss: 0.2175\n",
      "[25,   610] loss: 0.2350\n",
      "[25,   710] loss: 0.2608\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNNClassifier()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.00005)\n",
    "\n",
    "# Create data loader\n",
    "trainset = SampleDataset(X_train, Y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 32, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(25):  # Adjust number of epochs as needed\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 9:  # Print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.4f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'models/IMDB/model-full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNClassifier(\n",
       "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform inference with the saved model\n",
    "loaded_model = CNNClassifier()\n",
    "loaded_model.load_state_dict(torch.load('models/IMDB/model-full.pth'))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: 1.1369031410746189e-10\n"
     ]
    }
   ],
   "source": [
    "# Example inference\n",
    "sample_input = torch.randn(1, 1, 768)  # Example input\n",
    "output = loaded_model(sample_input)\n",
    "print(\"Model output:\", output.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do testing\n",
    "\n",
    "# Read pkl file \n",
    "with open('imdb-test-768.pkl', 'rb') as f:\n",
    "    test_vectors = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:04<00:00, 5038.51it/s]\n"
     ]
    }
   ],
   "source": [
    "gt = []\n",
    "preds = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(test_vectors))):\n",
    "    input_vector = torch.tensor(test_vectors[i].reshape(1, 1, 768))\n",
    "    actual = test_dataset[i]['label']\n",
    "    output = loaded_model(input_vector) \n",
    "    if output < 0.5:\n",
    "        pred = 0\n",
    "    else:\n",
    "        pred = 1\n",
    "    gt.append(actual)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668\n"
     ]
    }
   ],
   "source": [
    "# Print the number of misclassifications\n",
    "misc = 0\n",
    "for i in range(len(gt)):\n",
    "    if gt[i] != preds[i]:\n",
    "        misc += 1\n",
    "\n",
    "print(misc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89     12500\n",
      "           1       0.89      0.90      0.89     12500\n",
      "\n",
      "    accuracy                           0.89     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.89      0.89      0.89     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(gt, preds)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
